# BitCurrent Exchange - Logstash Pipeline Configuration

input {
  # Receive logs from services via TCP
  tcp {
    port => 5000
    codec => json_lines
  }

  # Kafka input for high-volume logs
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["logs"]
    codec => json
    group_id => "logstash-logs"
  }
}

filter {
  # Parse JSON logs
  if [message] =~ /^{.*}$/ {
    json {
      source => "message"
    }
  }

  # Add timestamp if not present
  if ![timestamp] {
    ruby {
      code => "event.set('timestamp', Time.now.to_i)"
    }
  }

  # Parse log level
  if [level] {
    mutate {
      uppercase => [ "level" ]
    }
  }

  # Extract service name from logger
  if [logger] {
    grok {
      match => { "logger" => "%{DATA:service}" }
    }
  }

  # Geo-IP lookup for IP addresses
  if [ip_address] {
    geoip {
      source => "ip_address"
      target => "geoip"
    }
  }

  # Tag security events
  if [event_type] =~ /login|2fa|withdrawal/ {
    mutate {
      add_tag => [ "security" ]
    }
  }

  # Tag errors
  if [level] == "ERROR" or [level] == "FATAL" {
    mutate {
      add_tag => [ "error" ]
    }
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "bitcurrent-logs-%{+YYYY.MM.dd}"
    document_type => "_doc"
  }

  # Also send critical errors to separate index
  if "error" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "bitcurrent-errors-%{+YYYY.MM.dd}"
    }
  }

  # Security events to dedicated index
  if "security" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "bitcurrent-security-%{+YYYY.MM.dd}"
    }
  }

  # Debug output (remove in production)
  # stdout {
  #   codec => rubydebug
  # }
}



